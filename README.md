# ğŸ§  YOLO-FAN-DETECTION

This project implements a custom **hand detection system** using the **YOLOv8 object detection framework**. It trains a neural network to detect **hands of a fan** in images and videos.

---

## ğŸ“‚ Project Structure

```bash
YOLO-FAN-DETECTION/
â”œâ”€â”€ trainval_images/          # Contains training + validation images
â”œâ”€â”€ test_images/              # Contains test images
â”œâ”€â”€ txt_labels/               # Raw label files before sorting
â”œâ”€â”€ dataset.yaml              # Dataset config for YOLOv8
â”œâ”€â”€ train.py                  # Code for training the YOLOv8 model
â”œâ”€â”€ validate_and_test.py      # Code for testing images and measuring performance
â”œâ”€â”€ fan_yolo_model.pt         # Trained model (if not tracked via Git LFS)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .gitignore                # Git ignore list
â””â”€â”€ README.md                 # This documentation


ğŸ§  Objective

The goal is to detect hands of fans in a custom dataset using YOLOv8, a state-of-the-art object detection architecture. The project covers:
	â€¢	Dataset preparation and labeling.
	â€¢	YOLOv8 training from scratch on custom data.
	â€¢	Image testing and inference.
	â€¢	Model evaluation and metrics (accuracy, precision, recall, mAP).

ğŸ“¦ Dataset Structure

You should organize your dataset into the following directory layout:
trainval_images/
â”œâ”€â”€ img1.jpg
â”œâ”€â”€ img2.jpg
â”œâ”€â”€ ...
â”œâ”€â”€ img1.txt   # YOLO label file
â”œâ”€â”€ img2.txt

test_images/
â”œâ”€â”€ test1.jpg
â”œâ”€â”€ test2.jpg
â”œâ”€â”€ ...
â”œâ”€â”€ test1.txt  # (Optional) for evaluation


ğŸ”– YOLO dataset.yaml

This file tells YOLO where your data and class names are:
path: .  # Root path to dataset
train: trainval_images
val: trainval_images  # or a separate val folder
test: test_images

names:
  0: FAN

ğŸ§ª Training the Model

Your training script train.py uses the Ultralytics YOLOv8 API:
from ultralytics import YOLO

model = YOLO("yolov8n.pt")  # Using YOLOv8 nano as base
model.train(data="dataset.yaml", epochs=50, imgsz=640, batch=16, name="fan_yolo_model2")

Run it with:
python main.py

The trained model will be saved to the runs/detect/fan_yolo_model2/weights/best.pt file.

ğŸ§ª Testing & Validation

To run inference on a test image and evaluate model performance:
from ultralytics import YOLO

model = YOLO("runs/detect/fan_yolo_model2/weights/best.pt")

# Run detection on a single image
results = model("test_images/test1.jpg", show=True, save=True)

# Evaluate model performance on test set
metrics = model.val(data="dataset.yaml")
print(metrics)

This will print metrics like:
	â€¢	mAP@0.5
	â€¢	Precision / Recall
	â€¢	Box loss / cls loss


ğŸ–¼ï¸ How to Test Custom Images
	1.	Place your image in a folder, e.g., test_images/test1.jpg
	2.	Run:

results = model("test_images/test1.jpg", show=True, save=True)
	3.	The output image with bounding boxes will be saved in the runs/detect/predict/ folder.

â— Common Issues
Issue
Solution
YOLO model not detecting anything
Ensure label .txt files match image filenames and are in YOLO format
GitHub wonâ€™t allow push
Remove large files (>100MB) and use .gitignore or Git LFS
Dataset not found
Check paths in dataset.yaml are correct
Model outputs wrong boxes
You may need more training epochs or better data balance


ğŸš€ Future Improvements
	â€¢	Use YOLOv8m or YOLOv8l for better accuracy.
	â€¢	Implement live video stream detection using OpenCV.
	â€¢	Integrate Streamlit/Gradio frontend for real-time testing.

ğŸ‘¨â€ğŸ’» Author

Ameer Mortaza
Ghulam Ishaq Khan Institute 
Website: Mortaza76.github.io


ğŸ“œ License

This project is open-sourced for educational and research purposes only. Please contact the author before using for commercial purposes.




















